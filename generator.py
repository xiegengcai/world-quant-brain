# -*- coding: utf-8 -*-


from collections import defaultdict
import pandas as pd
import constants
import wqb

import dataset_config
import factory
import utils
from AlphaMapper import AlphaMapper

class Generator:
    """
    AlphaÁîüÊàêÂô®
    """
    def __init__(
            self
            , wqbs:wqb.WQBSession
            , db_path:str='./db'
        ):
        """
        ÂàùÂßãÂåñ
        :param wqbs: wqb session
        :param dataset_id: Êï∞ÊçÆÈõÜid
        """
        self.wqbs = wqbs
        self.mapper = AlphaMapper(db_path)

    def process_datafields(self, df, data_type):
        """Â§ÑÁêÜÊï∞ÊçÆÂ≠óÊÆµ"""
        if data_type == "matrix":
            datafields = df[df['type'] == "MATRIX"]["id"].tolist()
        elif data_type == "vector":
            datafields = self.get_vec_fields(df[df['type'] == "VECTOR"]["id"].tolist())

        tb_fields = []
        for field in datafields:
            tb_fields.append("winsorize(ts_backfill(%s, 120), std=4)"%field)
        return tb_fields
    
    def get_vec_fields(self,fields):
        vec_ops = ["vec_avg", "vec_sum"]
        vec_fields = []
    
        for field in fields:
            for vec_op in vec_ops:
                if vec_op == "vec_choose":
                    vec_fields.append("%s(%s, nth=-1)"%(vec_op, field))
                    vec_fields.append("%s(%s, nth=0)"%(vec_op, field))
                else:
                    vec_fields.append("%s(%s)"%(vec_op, field))
    
        return(vec_fields)
    
    def generate_first_with_fields(self, fields:list):
        print(f"üìã Ê†πÊçÆÊåáÂÆöÂ≠óÊÆµÂàóË°®ÊûÑÂª∫...")
        first_order = factory.first_order_factory(fields, factory.ts_ops)
        print(f'üìã ÊûÑÂª∫ÁªìÊùüÔºåÂÖ±{len(first_order)}‰∏™Ë°®ËææÂºè, Ââç‰∫î‰∏™Ë°®ËææÂºèÂ¶Ç‰∏ã: \n{first_order[:5]}')
        sim_data_list =  factory.generate_sim_data('', first_order)
        print(f'üìã ÁîüÊàêÁªìÊùüÔºåÂÖ±{len(sim_data_list)}‰∏™alpha...')
        print(f'üìã ÂºÄÂßã‰øùÂ≠òalpha...')
        self.mapper.bath_save(sim_data_list)
        print(f'üìã ‰øùÂ≠òÁªìÊùü...')
    
    def generate_first(self, dataset_id:str):
        print(f"üìã Ëé∑ÂèñÊï∞ÊçÆÈõÜ{dataset_id}Â≠óÊÆµÂàóË°®...")
        # 1. Ëé∑ÂèñÊï∞ÊçÆÈõÜÂ≠óÊÆµ
        fields = utils.get_dataset_fields(self.wqbs, dataset_id)
        print(f'üìã Êï∞ÊçÆÈõÜ{dataset_id}ÂÖ±{len(fields)}‰∏™Â≠óÊÆµ...')
        # 2. Â§ÑÁêÜÊï∞ÊçÆÂ≠óÊÆµ
        df = pd.DataFrame(fields)
        print(f'üìã ÂºÄÂßãÂ§ÑÁêÜÂ≠óÊÆµ...')
        pc_fields = self.process_datafields(df, "matrix")
        print(f'üìã Â§ÑÁêÜÁªìÊùüÔºåÂÖ±{len(pc_fields)}‰∏™Â≠óÊÆµ...')
        print(f'üìã ÂºÄÂßãÊûÑÂª∫Ë°®ËææÂºè...')
        # 3. ÊûÑÂª∫Ë°®ËææÂºè
        first_order = factory.first_order_factory(pc_fields, factory.ts_ops)
        print(f'üìã ÊûÑÂª∫ÁªìÊùüÔºåÂÖ±{len(first_order)}‰∏™Ë°®ËææÂºè, Ââç‰∫î‰∏™Ë°®ËææÂºèÂ¶Ç‰∏ã: \n{first_order[:5]}')
        prefix= dataset_config.get_dataset_config(dataset_id)['field_prefix']
        sim_data_list =  factory.generate_sim_data(dataset_id, first_order)
        print(f'üìã ÁîüÊàêÁªìÊùüÔºåÂÖ±{len(sim_data_list)}‰∏™alpha...')
        print(f'üìã ÂºÄÂßã‰øùÂ≠òalpha...')
        self.mapper.bath_save(sim_data_list,field_prefix=prefix)
        print(f'üìã ‰øùÂ≠òÁªìÊùü...')

    def generate_second(self, group_ops:list,sharpe: float=1.2, fitness: float=1.0, self_corr: float=0.6):
        """
        Êü•ËØ¢‰∏ÄÈò∂ÁîüÊàê‰∫åÈò∂alpha
        :param sharpe: sharpeÁ≥ªÊï∞
        :param fitness: fitnessÁ≥ªÊï∞
        """
        page = 0

        while True:
            alphas = self.mapper.get_alphas(
                status=constants.ALPHA_STATUS_SYNC
                ,metrics={constants.IS_SHARPE: sharpe, constants.IS_FITNESS: fitness}
                , self_corr=0.6
                , step=1
                , page=page
            )
            if len(alphas) == 0:
                print(f'Ê≤°ÊúâÁ¨¶ÂêàÊù°‰ª∂[sharpe={sharpe}, fitness={fitness}, self_corr={self_corr}]ÁöÑ‰∏ÄÈò∂ÁöÑalpha...')
                break
            fo_tracker = self.handle_alphas(alphas, sharpe)
            fo_layer = self.prune(fo_tracker, 5)
            sim_data_list = self._generate_second(group_ops, fo_layer)
            print(f'üìã ÁîüÊàêÁªìÊùüÔºåÂÖ±{len(sim_data_list)}‰∏™alpha...')
            print(f'üìã ÂºÄÂßã‰øùÂ≠òalpha...')
            self.mapper.bath_save(sim_data_list,step=2)
            page += 1
        
    def _generate_second(self, group_ops:list,fo_layer):
        sim_data_list = []
        settings = dataset_config.default_settings
        for expr, decay in fo_layer:
            for alpha in factory.get_group_second_order_factory([expr], group_ops, self.region):
                # Êõ¥Êñ∞decay
                settings["decay"] = decay
                sim_data_list.append({
                    'type': 'REGULAR',
                    'settings': settings,
                    'regular': alpha
                })
        # random.shuffle(sim_data_list)

        return sim_data_list
    
    def generate_third(self, third_op:str, sharpe: float=1.4, fitness: float=1.0, self_corr: float=0.6):
        """
        Êü•ËØ¢‰∫åÈò∂ÁîüÊàê‰∏âÈò∂alpha
        :param sharpe: sharpeÁ≥ªÊï∞
        :param fitness: fitnessÁ≥ªÊï∞
        """
        page = 0
        while True:
            alphas = self.mapper.get_alphas(
                status=constants.ALPHA_STATUS_SYNC
                , metrics={constants.IS_SHARPE: sharpe, constants.IS_FITNESS: fitness}
                , self_corr=0.6
                , step=2
                , page=page
            )
            if len(alphas) == 0:
                print(f'Ê≤°ÊúâÁ¨¶ÂêàÊù°‰ª∂[sharpe={sharpe}, fitness={fitness}, self_corr={self_corr}]ÁöÑ‰∏ÄÈò∂ÁöÑalpha...')
                break
            fo_tracker = self.handle_alphas(alphas, sharpe)
            fo_layer = self.prune(fo_tracker, 5)
            sim_data_list = self._generate_second(third_op,fo_layer)
            print(f'üìã ÁîüÊàêÁªìÊùüÔºåÂÖ±{len(sim_data_list)}‰∏™alpha...')
            print(f'üìã ÂºÄÂßã‰øùÂ≠òalpha...')
            self.mapper.bath_save(sim_data_list,step=3)
            page += 1

    def _generate_third(self, third_op:str, fo_layer):
        sim_data_list = []
        settings = dataset_config.default_settings
        for expr, decay in fo_layer:
           for alpha in factory.trade_when_factory(third_op, expr):
                # Êõ¥Êñ∞decay
                settings["decay"] = decay
                sim_data_list.append({
                    'type': 'REGULAR',
                    'settings': settings,
                    'regular': alpha
                })
        # random.shuffle(sim_data_list)
        return sim_data_list
    def handle_alphas(self, alphas: list, sharpe) -> list:
        """
        Â§ÑÁêÜÊï∞ÊçÆ
        """
        output = []
        for alpha in alphas:
            longCount = alpha["longCount"]
            shortCount = alpha["shortCount"]
            #if (sharpe > 1.2 and sharpe < 1.6) or (sharpe < -1.2 and sharpe > -1.6):
            if (longCount + shortCount) > 100:
                longCount = alpha["longCount"]
                shortCount = alpha["shortCount"]
                alpha_id = alpha["id"]
                dateCreated = alpha["dateCreated"]
                sharpe = alpha["sharpe"]
                fitness = alpha["fitness"]
                turnover = alpha["turnover"]
                margin = alpha["margin"]
                
                decay = alpha["settings"]["decay"]
                exp = alpha['regular']
                if sharpe <= -sharpe:
                    exp = "-%s"%exp
                rec = [alpha_id, exp, sharpe, turnover, fitness, margin, dateCreated, decay]
                # print(rec)
                if turnover > 0.7:
                    rec.append(decay*4)
                elif turnover > 0.6:
                    rec.append(decay*3+3)
                elif turnover > 0.5:
                    rec.append(decay*3)
                elif turnover > 0.4:
                    rec.append(decay*2)
                elif turnover > 0.35:
                    rec.append(decay+4)
                elif turnover > 0.3:
                    rec.append(decay+2)
                output.append(rec)
        output.append(alpha['field_prefix'])
        return output

    def prune(self,next_alpha_recs, keep_num, prefix:str=''):
        # prefix is the datafield prefix, fnd6, mdl175 ...
        # keep_num is the num of top sharpe same-datafield alpha
        # ÊîæÂú®ÊúÄÂêé
        prefix = next_alpha_recs[-1]
        output = []
        num_dict = defaultdict(int)
        for rec in next_alpha_recs:
            exp = rec[1]
    
            if prefix != '' and prefix in exp:
                idx = exp.index(prefix)
                exp_tmp = exp[idx:-1]
                field = exp_tmp.split(",")[0]
            else:
                field = exp.split(prefix)[-1].split(",")[0]
            sharpe = rec[2]
            if sharpe < 0:
                field = "-%s"%field
            if num_dict[field] < keep_num:
                num_dict[field] += 1
                decay = rec[-1]
                exp = rec[1]
                output.append([exp,decay])
        return output
